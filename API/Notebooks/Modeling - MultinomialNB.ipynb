{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50a2237c-c160-4da8-9e04-b626d449c622",
   "metadata": {},
   "source": [
    "# Modeling - Multinomial Naive Bayes\n",
    "___\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737c6929-cbda-4fa2-b86b-67247a97f469",
   "metadata": {},
   "source": [
    "### Imports\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07243ef-63ed-40c7-a0ba-975918000a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all Libraries, Transformers, Models, and Plotting Tools\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7f1af8-cba5-4fb9-817f-939c75725cf9",
   "metadata": {},
   "source": [
    "#\n",
    "\n",
    "### Data and Features\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69356a4e-b6be-4627-847d-640ab3585317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Clean Combined Data Frame\n",
    "df = pd.read_csv('./data/df.csv')\n",
    "\n",
    "#Set X and y Variables\n",
    "X = df[['lemma_text']] \n",
    "y = df['poker']\n",
    "\n",
    "#Train/Test/Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, stratify=y, random_state=42)\n",
    "\n",
    "#Getting Baseline\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f01ca8-710f-47ff-a00d-3a3daedd724d",
   "metadata": {},
   "source": [
    "#\n",
    "\n",
    "### Modeling\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3ed0a094-b61f-4ded-9ebf-98bda1646840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/preetsekhon/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#instantiating count vectorizer \n",
    "cvec=CountVectorizer(stop_words='english')\n",
    "\n",
    "#Instantiating Stopwords and adding additional words added to stopwords list after initial word count EDA\n",
    "nltk.download('stopwords')\n",
    "stopwords = stopwords.words('english')\n",
    "stop_list = [\"dad\",\"poker\", \"say\", \"joke\"] \n",
    "stpwrd = nltk.corpus.stopwords.words('english')\n",
    "stpwrd.extend(stop_list)\n",
    "\n",
    "#Creating a Column Transformer to Model Non Sentiment Columns with Count Vectorizer\n",
    "ct1=make_column_transformer(\n",
    "    (cvec, 'lemma_text'), \n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "#Creating a Pipeline with Model \n",
    "transformer_pipe1 = Pipeline([\n",
    "    ('ct1',ct1),\n",
    "    ('mn',MultinomialNB())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f1fd4a-888b-481c-9135-bb1c2afe7a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting Transformer on Training Set \n",
    "transformer_pipe1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4abd81d-980f-4183-b158-efbabed77424",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scoring Data on Training Set\n",
    "transformer_pipe1.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8839e8-c3b4-4784-80e6-e350049b093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scoring Data on Test Set\n",
    "transformer_pipe1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9626e071-69fb-429e-83a2-6d521039cc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Predictions\n",
    "preds_pipe = transformer_pipe1.predict(X_test)\n",
    "\n",
    "# Calculate the specificity and precision\n",
    "print(classification_report(y_test, preds_pipe, target_names=['Dad Jokes', 'Poker']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0646fa88-c5e6-4047-b0e5-aa5dbdb0106f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Confusion Matrix and Saving Plot to Folder\n",
    "plot_confusion_matrix(transformer_pipe1,X_test,y_test,display_labels=['Dad Jokes','Poker'])\n",
    "plt.title('MultiNomial NB')\n",
    "plt.savefig('visuals/MN_CM.jpeg',dpi=300, bbox_inches = \"tight\")\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
